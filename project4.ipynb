{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9929c1a-c19b-4f3b-985b-84e4b505bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29446c85-d025-4477-b13b-5f801de994e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "\n",
    "df = df.rename({'num':'disease'}, axis=1)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "display(df.head(5))\n",
    "sns.displot(data=df, x='age', hue='disease')\n",
    "# Plot histograms\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# make a little extra space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "ax1.hist(df[df.disease == 0].age);\n",
    "# ax1.set_xlabel('age');\n",
    "ax1.set_ylabel('number of patients');\n",
    "ax1.set_xlim(20, 80);\n",
    "ax1.set_ylim(0, 50);\n",
    "ax1.set_title('healthy');\n",
    "\n",
    "ax2.hist(df[df.disease == 1].age, color='orange');\n",
    "ax2.set_xlabel('age');\n",
    "ax2.set_ylabel('number of patients');\n",
    "ax2.set_xlim(20, 80);\n",
    "ax2.set_ylim(0, 50);\n",
    "ax2.set_title('unhealthy');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3aae22-e09e-4403-bd6e-7117a77fb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use knn on age. First create a nearest neighbors object.\n",
    "nn = NearestNeighbors(n_neighbors=5, metric='euclidean', algorithm='auto')\n",
    "\n",
    "# Create a two-dimensional array. This is basically a one-dimensional array with\n",
    "# single-element arrays of patient ages in the second dimension. We're going to\n",
    "# search for neighbors using only the age dimension.\n",
    "X = [[x] for x in df.age]\n",
    "X\n",
    "\n",
    "# This builds an index data structure under the hood for query performance\n",
    "fit = nn.fit(X)\n",
    "\n",
    "# Find the k nearest neighbors\n",
    "distances, indices = fit.kneighbors([[70]])\n",
    "display(distances)\n",
    "display(indices)\n",
    "distances, indices\n",
    "\n",
    "# Get the patients that are near the age\n",
    "nbrs = df.iloc[indices[0]]\n",
    "display(nbrs)\n",
    "\n",
    "# Print how many patients are sick and how many are healthy\n",
    "healthy = nbrs[nbrs.disease == 0].count().disease\n",
    "sick = nbrs[nbrs.disease == 1].count().disease\n",
    "print('healthy: {}\\nsick: {}'.format(healthy, sick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d88126-077d-4b35-a72e-11ee238425a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "## From what I understand, the below is doing this:\n",
    "## 1. getting all of the values and doing nn.fit(X) to do something cool\n",
    "## 2. getting a sample of the data based on n\n",
    "## 3. taking the sample, and grabbing the values for disease, age, etc, for each of them\n",
    "## 4. We are then grabbing the k-nearest neighbors of each sample based on patientsX (age, trestbps, each of the patients data).\n",
    "## 5. Predict all of them\n",
    "\n",
    "# Use knn on age. First create a nearest neighbors object.\n",
    "nn = NearestNeighbors(n_neighbors=6, metric='euclidean', algorithm='auto')\n",
    "# This builds an index data structure under the hood for query performance\n",
    "X = df[['age', 'trestbps']].values\n",
    "\n",
    "fit = nn.fit(X)\n",
    "\n",
    "# Get random patients to test on\n",
    "n = 50\n",
    "patients = df.sample(n)\n",
    "display(patients)\n",
    "patientsX = patients[['age','trestbps']].values\n",
    "display(patientsX)\n",
    "\n",
    "patientsy = patients[['disease']].values\n",
    "display(patientsy)\n",
    "\n",
    "# # Find the k nearest neighbors to the patient.\n",
    "distances, indices = fit.kneighbors(patientsX)\n",
    "# # print('indices of k-nearest neighbors for each patient:')\n",
    "display(indices)\n",
    "\n",
    "# y_pred = []\n",
    "# for i in range(n):\n",
    "#     # print('nearest neighbors to patient: {}:'.format(patientsX[i]))\n",
    "#     nbrs = df.iloc[indices[i]]\n",
    "#     # Drop the patient of interest\n",
    "#     nbrs = nbrs.drop(patients.index[i])\n",
    "#     # display(nbrs)\n",
    "\n",
    "#     healthy = nbrs[nbrs.disease == 0].count().disease\n",
    "#     sick = nbrs[nbrs.disease == 1].count().disease\n",
    "#     predict = 0 if (healthy > sick) else 1\n",
    "#     print(f'healthy: {healthy}, sick: {sick}, predicted: {predict}, actual: {patientsy[i][0]}')\n",
    "#     y_pred.append(predict)\n",
    "\n",
    "# # This is where we would compile how many patients are predicted\n",
    "# # correctly. Remember:\n",
    "# #    precision = tp/(tp+fp)  (\"sloppiness\")\n",
    "# #    recall    = tp/(tp+fn)  (\"What percentage did we find?\")\n",
    "# #    f-score - a balance between precision and recall\n",
    "# #    support - number of positive labels\n",
    "# (p,r,f,s) = precision_recall_fscore_support(patientsy, y_pred, labels=[0,1])\n",
    "# print(f'precision={p}, recall={r}, f-score={f}, support={s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486da7a-ba8a-4c74-b2da-e201e5b2b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9ce11-7850-48d8-82df-84cf46de3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1618bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "df.rename(columns={'num': 'disease'}, inplace=True)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "df.loc[df['ca'] == '?', 'ca'] = None\n",
    "df.loc[df['thal'] == '?', 'thal'] = None\n",
    "df['ca'] = df['ca'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "df['thal'] = df['thal'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "display(df)\n",
    "df.dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDataset(dataframe, testCol, k=5, attributes=1, verbose=True):\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Test a random set of attributes\n",
    "    if type(attributes) == int:\n",
    "        # If more attributes are specified than there are, just use all of them\n",
    "        if attributes > len(df.columns)-1:\n",
    "            attributes = len(df.columns)-1\n",
    "        attributes = df[df.columns[df.columns != testCol]].sample(axis=1, n=attributes).columns\n",
    "\n",
    "    # Test a specific set of attributes\n",
    "    elif type(attributes) != list:\n",
    "        print('attributes must be an integer or a list of attribute names')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Clear out any records that don't have a valid value for one of the attributes in question\n",
    "    for attribute in attributes:\n",
    "        if attribute == testCol:\n",
    "            print(f'Cannot predict {testCol} using {testCol}')\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            df = df.dropna(subset=attribute)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "    \n",
    "    print(f'Predicting based on the {k} nearest neighbors using {attributes}:') if verbose else None\n",
    "    # display(df)\n",
    "\n",
    "    # Standardize the data\n",
    "    for attribute in attributes:\n",
    "        df[attribute] = (df[attribute] - df[attribute].mean()) / df[attribute].std()\n",
    "\n",
    "    f1Scores = []\n",
    "    for j in range(10):\n",
    "        # Use knn. First create a nearest neighbors object.\n",
    "        nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "        \n",
    "        X = df[attributes].values\n",
    "        y = df[[testCol]].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)#, random_state=42)\n",
    "\n",
    "        fit = nn.fit(X_train)\n",
    "\n",
    "        distances, indices = fit.kneighbors(X_test)\n",
    "\n",
    "        y_pred = []\n",
    "        for i in range(len(indices)):\n",
    "            nbrs = y_train[indices[i]]\n",
    "\n",
    "            # Predict the class with the highest frequency among neighbors\n",
    "            greatestValue = df[testCol].unique()[0]\n",
    "            greatestValueCount = 0\n",
    "            for value in df[testCol].unique():\n",
    "                valueCount = [item for sublist in nbrs for item in sublist].count(value)\n",
    "                if valueCount >= greatestValueCount:\n",
    "                    greatestValueCount = valueCount\n",
    "                    greatestValue = value\n",
    "\n",
    "            # healthy = [item for sublist in nbrs for item in sublist].count(0)\n",
    "            # sick = [item for sublist in nbrs for item in sublist].count(1)\n",
    "            predict = greatestValue\n",
    "            # print(healthy, sick, predict)\n",
    "\n",
    "            y_pred.append(predict)\n",
    "        \n",
    "        (p,r,f,s) = precision_recall_fscore_support(y_test, y_pred)\n",
    "        f1Scores.append(f)\n",
    "        print(f'Test {j}: precision={p}, recall={r}, f-score={f}, support={s}') if verbose else None\n",
    "\n",
    "    meanF1s = []\n",
    "    for i in range(len(f1Scores[0])):\n",
    "        f1Total = 0\n",
    "        for score in f1Scores:\n",
    "            f1Total += score[i]\n",
    "        meanF1s.append(f1Total / len(f1Scores))\n",
    "\n",
    "    print(f'Mean F1 scores: f-score={meanF1s}') if verbose else None\n",
    "\n",
    "    f1sTotal = 0\n",
    "    for f1 in meanF1s:\n",
    "        f1sTotal += f1\n",
    "    meanOfF1s = f1sTotal / len(meanF1s)\n",
    "    meanF1s.append(meanOfF1s)\n",
    "\n",
    "    print(f'Mean of mean F1 scores: f-score={meanF1s[-1]}') if verbose else None\n",
    "\n",
    "    return meanF1s\n",
    "\n",
    "\n",
    "scores = {'k': [], 'scores': []}\n",
    "for k in range(1, 200):\n",
    "    scores['k'].append(k)\n",
    "    scores['scores'].append(testDataset(dataframe=df, testCol='disease', k=k, attributes=['oldpeak', 'cp'], verbose=False))\n",
    "\n",
    "plt.plot(scores['k'], scores['scores'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('f score')\n",
    "\n",
    "# testDataset(df, 'disease', 5, ['oldpeak', 'thal', 'ca'])\n",
    "# testDataset(df, 'disease', 5, ['thalach', 'ca', 'thal'])\n",
    "# testDataset(df, 'disease', 5, ['oldpeak', 'age', 'cp'])\n",
    "# testDataset(df, 'disease', 5, ['slope', 'thal', 'cp'])\n",
    "testDataset(df, 'disease', 5, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
