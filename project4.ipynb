{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf5e0cc",
   "metadata": {},
   "source": [
    "# Project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486da7a-ba8a-4c74-b2da-e201e5b2b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import viridis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8592202",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleveland.csv')\n",
    "df.rename(columns={'num': 'disease'}, inplace=True)\n",
    "df['disease'] = df.disease.apply(lambda x: min(x, 1))\n",
    "df.loc[df['ca'] == '?', 'ca'] = None\n",
    "df.loc[df['thal'] == '?', 'thal'] = None\n",
    "df['ca'] = df['ca'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "df['thal'] = df['thal'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "display(df)\n",
    "df.dropna().corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3b697",
   "metadata": {},
   "source": [
    "### Testing predictions using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDataset(dataframe, testCol, k=5, attributes=1, verbose=True):\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Test a random set of attributes\n",
    "    if type(attributes) == int:\n",
    "        # If more attributes are specified than there are, just use all of them\n",
    "        if attributes > len(df.columns)-1:\n",
    "            attributes = len(df.columns)-1\n",
    "        attributes = df[df.columns[df.columns != testCol]].sample(axis=1, n=attributes).columns\n",
    "\n",
    "    # Test a specific set of attributes\n",
    "    elif type(attributes) != list:\n",
    "        print('attributes must be an integer or a list of attribute names')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Clear out any records that don't have a valid value for one of the attributes in question\n",
    "    for attribute in attributes:\n",
    "        if attribute == testCol:\n",
    "            print(f'Cannot predict {testCol} using {testCol}')\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            df = df.dropna(subset=attribute)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "    \n",
    "    print(f'Predicting based on the {k} nearest neighbors using {attributes}:') if verbose else None\n",
    "    # display(df)\n",
    "\n",
    "    # Standardize the data\n",
    "    for attribute in attributes:\n",
    "        df[attribute] = (df[attribute] - df[attribute].mean()) / df[attribute].std()\n",
    "\n",
    "    f1Scores = []\n",
    "    for j in range(10):\n",
    "        # Use knn. First create a nearest neighbors object.\n",
    "        nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "        \n",
    "        X = df[attributes].values\n",
    "        y = df[[testCol]].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)#, random_state=42)\n",
    "\n",
    "        fit = nn.fit(X_train)\n",
    "\n",
    "        distances, indices = fit.kneighbors(X_test)\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(len(indices)):\n",
    "            nbrs = y_train[indices[i]]\n",
    "            \n",
    "\n",
    "            # Predict the class with the highest frequency among neighbors\n",
    "            greatestValue = df[testCol].unique()[0]\n",
    "\n",
    "            greatestValueCount = 0\n",
    "            for value in df[testCol].unique():\n",
    "                valueCount = [item for sublist in nbrs for item in sublist].count(value)\n",
    "\n",
    "                if valueCount >= greatestValueCount:\n",
    "                    greatestValueCount = valueCount\n",
    "                    greatestValue = value\n",
    "\n",
    "            # healthy = [item for sublist in nbrs for item in sublist].count(0)\n",
    "            # sick = [item for sublist in nbrs for item in sublist].count(1)\n",
    "            predict = greatestValue\n",
    "            # print(healthy, sick, predict)\n",
    "\n",
    "            y_pred.append(predict)\n",
    "        \n",
    "        (p,r,f,s) = precision_recall_fscore_support(y_test, y_pred, zero_division = 0)\n",
    "        f1Scores.append(f)\n",
    "        print(f'Test {j}: precision={p}, recall={r}, f-score={f}, support={s}') if verbose else None\n",
    "\n",
    "    meanF1s = []\n",
    "    for i in range(len(f1Scores[0])):\n",
    "        f1Total = 0\n",
    "        for score in f1Scores:\n",
    "            f1Total += score[i]\n",
    "        meanF1s.append(f1Total / len(f1Scores))\n",
    "\n",
    "    print(f'Mean F1 scores: f-score={meanF1s}') if verbose else None\n",
    "\n",
    "    f1sTotal = 0\n",
    "    for f1 in meanF1s:\n",
    "        f1sTotal += f1\n",
    "    meanOfF1s = f1sTotal / len(meanF1s)\n",
    "    meanF1s.append(meanOfF1s)\n",
    "\n",
    "    print(f'Mean of mean F1 scores: f-score={meanF1s[-1]}') if verbose else None\n",
    "\n",
    "    return meanF1s, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fd425",
   "metadata": {},
   "source": [
    "#### Running random tests to find some promising combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testDataset(df, 'disease', 5, ['oldpeak', 'cp'])\n",
    "# testDataset(df, 'disease', 5, ['thalach', 'ca', 'thal'])\n",
    "# testDataset(df, 'disease', 5, ['oldpeak', 'age', 'cp'])\n",
    "# testDataset(df, 'disease', 5, ['slope', 'thal', 'cp'])\n",
    "testDataset(df, 'disease', 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c24990",
   "metadata": {},
   "source": [
    "#### Testing different k values on a promising combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'k': [], 'scores': []}\n",
    "for k in range(1, 200):\n",
    "    scores['k'].append(k)\n",
    "    fScores, attributes = testDataset(dataframe=df, testCol='disease', k=k, attributes=['oldpeak', 'cp'], verbose=False)\n",
    "    scores['scores'].append(fScores)\n",
    "\n",
    "plt.plot(scores['k'], scores['scores'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('f score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880a7e3",
   "metadata": {},
   "source": [
    "#### Testing combinations of k values and numbers of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9ce11-7850-48d8-82df-84cf46de3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = 11\n",
    "\n",
    "# Create a color map\n",
    "colors = viridis(np.linspace(0, 1, num_attributes))\n",
    "highestKs = []\n",
    "highestFScores = []\n",
    "bestAttributes = []\n",
    "# Plot each curve with a different color based on the number of attributes\n",
    "for j in range(1, num_attributes + 1):\n",
    "    scores = {'k': [], 'scores': [], 'attributes': []}\n",
    "    highestFScore = 0\n",
    "    highestK = 0\n",
    "    bestAttribute = []\n",
    "    for k in range(1, 50):\n",
    "        scores['k'].append(k)\n",
    "        new_scores, randomAttributes = testDataset(dataframe=df, testCol='disease', k=k, attributes=j, verbose=False)\n",
    "        scores['scores'].append(new_scores[2])\n",
    "\n",
    "        if highestFScore < new_scores[2]:\n",
    "            highestFScore = new_scores[2]\n",
    "            highestK = k\n",
    "            bestAttribute = randomAttributes\n",
    "\n",
    "    # Use a different color for each curve\n",
    "    plt.plot(scores['k'], scores['scores'], label=f\"{j} attributes\", color=colors[j-1])\n",
    "    highestKs.append(highestK)\n",
    "    highestFScores.append(highestFScore)\n",
    "    bestAttributes.append(randomAttributes)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('f score')\n",
    "plt.title('Performance vs. k for Different Number of Attributes')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "display(highestKs)\n",
    "display(highestFScores)\n",
    "display(bestAttributes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607128e9-e4f4-4d81-b55c-21d1ab0e54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_value = max(highestFScores)\n",
    "index_of_max = highestFScores.index(max_value)\n",
    "\n",
    "\n",
    "display(testDataset(df, 'disease', highestKs[index_of_max], list(bestAttributes[index_of_max])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c19d9-e4cc-41c9-9596-4c59e1a61261",
   "metadata": {},
   "source": [
    "#### Arriving on a winning combination\n",
    "\n",
    "Given the results of the test we ran, we are 'usually' around 10 or 11 attributes, so hand select that many. It is also between 20 and 35 K values 'usually', so use that many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ebd95-3e49-4fcd-8b75-b41f500474e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributesToTest = ['age', 'sex','cp','trestbps','chol','fbs','restecg','ca','oldpeak','exang','thal']\n",
    "display(testDataset(df, 'disease', 25, attributesToTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9fd46",
   "metadata": {},
   "source": [
    "### Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0930bd5-3995-4fb3-aae9-1e66a7e9fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def challenge(testDataFrame, trainDataFrame, testCol, k=5, attributes=1, verbose=True):\n",
    "    testDF = testDataFrame.copy()\n",
    "    trainDF = trainDataFrame.copy()\n",
    "\n",
    "    # Test a random set of attributes\n",
    "    if type(attributes) == int:\n",
    "        # If more attributes are specified than there are, just use all of them\n",
    "        if attributes > len(testDF.columns)-1:\n",
    "            attributes = len(testDF.columns)-1\n",
    "        attributes = testDF[testDF.columns[testDF.columns != testCol]].sample(axis=1, n=attributes).columns\n",
    "\n",
    "    # Test a specific set of attributes\n",
    "    elif type(attributes) != list:\n",
    "        print('attributes must be an integer or a list of attribute names')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Clear out any records that don't have a valid value for one of the attributes in question\n",
    "    for attribute in attributes:\n",
    "        if attribute == testCol:\n",
    "            print(f'Cannot predict {testCol} using {testCol}')\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            testDF = testDF.dropna(subset=attribute)\n",
    "            trainDF = trainDF.dropna(subset=attribute)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "    \n",
    "    print(f'Predicting based on the {k} nearest neighbors using {attributes}:') if verbose else None\n",
    "    # display(testDF)\n",
    "\n",
    "    # Standardize the data\n",
    "    for attribute in attributes:\n",
    "        testDF[attribute] = (testDF[attribute] - testDF[attribute].mean()) / testDF[attribute].std()\n",
    "        trainDF[attribute] = (trainDF[attribute] - trainDF[attribute].mean()) / trainDF[attribute].std()\n",
    "    \n",
    "    # Use knn. First create a nearest neighbors object.\n",
    "    nn = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='auto')\n",
    "    \n",
    "    X_train = trainDF[attributes].values\n",
    "    X_test = testDF[attributes].values\n",
    "    y_train = trainDF[[testCol]].values\n",
    "    y_test = testDF[[testCol]].values\n",
    "\n",
    "    fit = nn.fit(X_train)\n",
    "\n",
    "    distances, indices = fit.kneighbors(X_test)\n",
    "    \n",
    "    y_pred = []\n",
    "    for i in range(len(indices)):\n",
    "        nbrs = y_train[indices[i]]\n",
    "        \n",
    "\n",
    "        # Predict the class with the highest frequency among neighbors\n",
    "        greatestValue = trainDF[testCol].unique()[0]\n",
    "\n",
    "        greatestValueCount = 0\n",
    "        for value in trainDF[testCol].unique():\n",
    "            valueCount = [item for sublist in nbrs for item in sublist].count(value)\n",
    "\n",
    "            if valueCount >= greatestValueCount:\n",
    "                greatestValueCount = valueCount\n",
    "                greatestValue = value\n",
    "\n",
    "        # healthy = [item for sublist in nbrs for item in sublist].count(0)\n",
    "        # sick = [item for sublist in nbrs for item in sublist].count(1)\n",
    "        predict = greatestValue\n",
    "        # print(healthy, sick, predict)\n",
    "\n",
    "        y_pred.append(predict)\n",
    "        \n",
    "    (p,r,f,s) = precision_recall_fscore_support(y_test, y_pred, zero_division = 0)\n",
    "    print(f'precision={p}, recall={r}, f-score={f}, support={s}') if verbose else None\n",
    "\n",
    "    f1Total = 0\n",
    "    for f1 in f:\n",
    "        f1Total += f1\n",
    "    meanF1 = f1Total / len(f)\n",
    "\n",
    "    print(f'Mean of F1 scores: f-score={meanF1}') if verbose else None\n",
    "    \n",
    "    f1Scores = f.tolist()\n",
    "    f1Scores.append(meanF1)\n",
    "\n",
    "    return f1Scores, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01e508",
   "metadata": {},
   "source": [
    "#### Cleaning the challenge test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "challengeDataset = 'cleveland-test-sample.csv'\n",
    "challengeDF = pd.read_csv(challengeDataset)\n",
    "challengeDF.rename(columns={'num': 'disease'}, inplace=True)\n",
    "challengeDF['disease'] = challengeDF.disease.apply(lambda x: min(x, 1))\n",
    "challengeDF.loc[challengeDF['ca'] == '?', 'ca'] = None\n",
    "challengeDF.loc[challengeDF['thal'] == '?', 'thal'] = None\n",
    "challengeDF['ca'] = challengeDF['ca'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "challengeDF['thal'] = challengeDF['thal'].apply(lambda a: float(a) if (a is not None) else None)\n",
    "display(challengeDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a338df",
   "metadata": {},
   "source": [
    "#### Running a prediction on the challenge dataset using the optimal attributes and k value for a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributesToTest = ['age', 'sex','cp','trestbps','chol','fbs','restecg','ca','oldpeak','exang','thal']\n",
    "k = 25\n",
    "display(challenge(testDataFrame=challengeDF, trainDataFrame=df, testCol='disease', k=k, attributes=attributesToTest, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfd13e",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc890a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
